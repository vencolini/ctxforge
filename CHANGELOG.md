# Changelog

All notable changes to ctxforge will be documented in this file.

The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),
and this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).

## [3.1.0] - 2025-10-22

### âœ¨ New Protocol: Landing Page Design

**Added comprehensive protocol for creating high-converting marketing landing pages.**

### Added

- **LANDING-PAGE-DESIGN.md Protocol** (~5K tokens, 1,133 lines)
  - 7 expert-formulated discovery questions focused on conversion psychology
  - Business goal & conversion action discovery
  - Target audience pain point identification
  - Unique value proposition extraction
  - Trust signals & social proof requirements
  - Objection handling discovery
  - Traffic source & message matching
  - Success metrics & constraints definition

- **Industry-Specific Page Patterns**
  - SaaS (free trial / demo focused)
  - B2B Services (consultation booking focused)
  - B2C E-commerce (purchase focused)
  - Lead Generation (email capture focused)
  - Each with proven structures and conversion benchmarks

- **Copy Framework Library**
  - PAS (Problem-Agitate-Solution) for pain-driven offers
  - AIDA (Attention-Interest-Desire-Action) for educational content
  - Value Proposition Canvas for competitive markets
  - Featureâ†’Benefit translation templates
  - Framework-agnostic HTML structure examples

- **Comprehensive Quality Standards**
  - Conversion psychology checklist (8 criteria)
  - Visual hierarchy optimization (8 criteria)
  - Performance requirements (<2.5s LCP critical for conversion)
  - Mobile optimization (thumb-reachable CTAs, readable fonts)
  - Accessibility compliance (WCAG AA)
  - SEO & discoverability best practices
  - A/B testing readiness verification

- **Industry Conversion Benchmarks**
  - SaaS: 2-5% average, 10-15% top performers
  - B2B Lead Generation: 5-10% average, 15-20% with strong offers
  - B2C E-commerce: 2-3% average, varies by price point
  - Webinar Registration: 20-40% average
  - Lead Magnet Downloads: 25-50% average

### Improvements

- **Intent Detection** - Added `LANDING_PAGE_DESIGN` to CORE.md
  - Keywords: "landing page", "sales page", "marketing page", "conversion page", "campaign page", "promotional page", "product page"
  - Auto-loads protocol when user requests landing page creation

- **Protocol Integration** - Seamless handoff to FEATURE-DEVELOPMENT
  - After landing page structure approved, delegates technical implementation
  - Framework-agnostic design specification
  - Clear implementation handoff process

### Documentation

- **README.md** - Updated protocol count from 15 to 16
  - Added LANDING-PAGE-DESIGN to Available Protocols table
  - Added to Protocol Auto-Loading examples
  - Updated Component Structure diagram

- **CORE.md** - Updated intent detection and protocol mapping tables
  - Line 102: Added LANDING_PAGE_DESIGN intent with keywords
  - Line 145: Added protocol file mapping with ~5K token estimate

### Use Cases

Perfect for:
- SaaS product launches and trial signup pages
- B2B service provider marketing pages
- E-commerce single-product promotional pages
- Webinar and lead magnet registration pages
- Campaign-specific conversion-optimized pages

Trigger examples:
- "Create landing page for SaaS trial"
- "Design marketing page for product launch"
- "Build conversion page for webinar registration"
- "Optimize sales page for better conversion"

---

## [3.0.5] - 2025-10-22

### Complete v3.0 Protocol System

**Full commitment to modular protocol architecture with significant improvements.**

### Improvements

- **Complete Intent Detection** - Added 8 missing protocols to CORE.md intent table
  - DOCUMENTATION, PERFORMANCE_OPTIMIZATION, SECURITY_AUDIT
  - ARCHITECTURE_DESIGN, DEPENDENCY_MANAGEMENT, DEPLOYMENT
  - PAIR_PROGRAMMING, LEARNING, DATABASE_MIGRATION
  - All 15 protocols now accessible via automatic intent detection

- **Keyword Conflict Resolution** - Improved specificity to reduce protocol mismatches
  - REFACTOR: Changed "optimize" to "restructure" (avoid PERFORMANCE_OPTIMIZATION conflict)
  - INVESTIGATION: More specific triggers ("investigate", "debug", "root cause")
  - PERFORMANCE_OPTIMIZATION: Explicit keywords ("optimize performance", "speed up", "bottleneck")
  - ARCHITECTURE_DESIGN: Clearer terms ("system design", "structure project")

### Breaking Changes

- **Removed LLM-INSTRUCTIONS.md** (v2.0 legacy file, 889 lines)
  - Full migration to v3.0 modular protocol system
  - All v2.0 references eliminated from framework

### Documentation

- **FRAMEWORK.md** - Updated to v3.0, marked as human-only reference
- **QUICK-RELOAD.md** - Updated all references from LLM-INSTRUCTIONS.md to CORE.md
- **README.md** - Corrected token cost claims to match reality
  - CORE.md: 5K â†’ 2.7K tokens (was overestimated)
  - Session total: 8-10K â†’ 4-9K tokens (avg 6K)
  - File count: 21 â†’ 20 files

### Performance

- **Token Savings:** ~5K tokens saved per session
- **Efficiency Gain:** 85% reduction from v2.0, 40% improvement from initial v3.0 estimates
- **Framework Overhead:** Now 4-9K per session (down from 8-10K claimed)

---

## [3.0.2] - 2025-10-02

### ðŸ› Fixes

- **validate command** - Updated to check v3.0 structure (CORE.md, protocols/, etc.)
- **status command** - Updated to read project.md instead of old CONTEXT.md
- Both commands now correctly validate v3.0 protocol auto-loading system

### ðŸ§ª Testing

- **test-commands.sh** - Added comprehensive CLI command test script
- All commands now tested and working: init, validate, status, health, optimize, version

---

## [3.0.1] - 2025-10-02

### ðŸ“š Documentation

- **README.md Complete Rewrite** - Updated for v3.0 protocol auto-loading system
  - Protocol auto-loading architecture explanation
  - All 15 specialized protocols documented
  - Token efficiency comparison (60-70% reduction)
  - Universal LLM compatibility highlighted
  - Platform integration examples (12+ platforms)
  - Real-world workflow examples
  - Updated quick start guide using CORE.md
  - Migration guide from v2.x
  - FAQ section updated for v3.0
  - Token budget comparison tables
- **Installation Guide** - Updated to reflect v3.0 file structure
- **Integration Examples** - Clarified example-integrations/ folder purpose

### ðŸ› Fixes

- Fixed outdated documentation references to v2.0
- Corrected token count documentation (now accurate for v3.0)

---

## [3.0.0] - 2025-10-02

### ðŸš€ Major Release: Protocol Auto-Loading System

**Revolutionary architecture that loads only the protocol you need, when you need it.**

### âœ¨ Game-Changing Features

#### Protocol Auto-Loading (60-70% Token Reduction)
- **Before (v2.1):** Load entire 25K token framework every session
- **After (v3.0):** Load 5K CORE.md + 4K protocol = 9K tokens per session
- **Result:** 60-70% token reduction = 2-3x more code fits in context!

#### Intelligent Intent Detection
```
Your request: "Add user login"
     â†“
CORE.md detects: FEATURE_DEVELOPMENT intent
     â†“
Auto-loads: protocols/FEATURE-DEVELOPMENT.md
     â†“
Executes: Discovery â†’ Inferences â†’ Implementation
```

No manual protocol selection needed. Just describe what you want.

#### 15 Specialized Protocols
Each protocol is a complete, standalone workflow file:

1. **FEATURE-DEVELOPMENT.md** - Build new functionality
2. **BUG-FIXING.md** - Diagnose and fix bugs
3. **REFACTORING.md** - Improve code quality
4. **CODE-REVIEW.md** - Quality assessment
5. **TESTING.md** - Write comprehensive tests
6. **INVESTIGATION.md** - Understand how code works
7. **DOCUMENTATION.md** - Write docs and README files
8. **PERFORMANCE-OPTIMIZATION.md** - Make code faster
9. **SECURITY-AUDIT.md** - Find vulnerabilities
10. **ARCHITECTURE-DESIGN.md** - Design system architecture
11. **DEPENDENCY-MANAGEMENT.md** - Add/update packages
12. **DEPLOYMENT.md** - Deploy to production
13. **PAIR-PROGRAMMING.md** - Collaborative development
14. **LEARNING.md** - Teaching and tutorials
15. **DATABASE-MIGRATION.md** - Schema changes

#### Unlimited Scalability
- **v2.1 Problem:** Adding 1 protocol = +3K tokens for EVERY session (unsustainable)
- **v3.0 Solution:** Adding 1 protocol = +0 tokens unless used
  - 15 protocols = still only 9K per session
  - Can add 100 protocols without impacting performance!

#### Multi-Protocol Sessions
- **v2.1:** One protocol per session (reloading is expensive)
- **v3.0:** Switch protocols seamlessly in same session
  - Example: Fix bug â†’ Write test â†’ Deploy (3 protocols, one chat)

### ðŸŽ¯ New Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Your Request   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   CORE.md       â”‚ â† 5K tokens (always loaded)
â”‚ Intent Detectionâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“ Detects intent
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Auto-load 1 Protocol       â”‚ â† 3-5K tokens (only what's needed)
â”‚  protocols/[INTENT].md      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Execute Workflowâ”‚ (Discovery â†’ Implementation â†’ Documentation)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ðŸ“¦ Installation Changes

**New structure:**
```
docs/context/
â”œâ”€â”€ CORE.md                          # Entry point (5K tokens)
â”œâ”€â”€ FRAMEWORK.md                     # Human reference guide
â”œâ”€â”€ PERFORMANCE-DIRECTIVES.md        # Quality rules
â”œâ”€â”€ DISCOVERY-QUESTIONS.md           # Question templates
â”œâ”€â”€ TEMPLATES.md                     # Document structures
â”œâ”€â”€ QUICK-RELOAD.md                  # Recovery guide
â”œâ”€â”€ project.md                       # Created by LLM
â””â”€â”€ protocols/                       # 15 specialized protocols
    â”œâ”€â”€ FEATURE-DEVELOPMENT.md       # Auto-loaded on demand
    â”œâ”€â”€ BUG-FIXING.md
    â”œâ”€â”€ REFACTORING.md
    â”œâ”€â”€ CODE-REVIEW.md
    â”œâ”€â”€ TESTING.md
    â”œâ”€â”€ INVESTIGATION.md
    â”œâ”€â”€ DOCUMENTATION.md
    â”œâ”€â”€ PERFORMANCE-OPTIMIZATION.md
    â”œâ”€â”€ SECURITY-AUDIT.md
    â”œâ”€â”€ ARCHITECTURE-DESIGN.md
    â”œâ”€â”€ DEPENDENCY-MANAGEMENT.md
    â”œâ”€â”€ DEPLOYMENT.md
    â”œâ”€â”€ PAIR-PROGRAMMING.md
    â”œâ”€â”€ LEARNING.md
    â””â”€â”€ DATABASE-MIGRATION.md
```

**Total:** 21 files, ~100K tokens in library
**Per session:** 8-10K tokens loaded (only what you need!)

### ðŸŽ¯ Universal Command

Works with **any LLM:**
```
Read docs/context/CORE.md and ask what I want to work on
```

That's it. No configuration. No setup.

### ðŸŒ Universal Compatibility

âœ… Claude / Claude Code
âœ… ChatGPT / GPT-4
âœ… Google Gemini
âœ… GitHub Copilot
âœ… Cursor
âœ… Codeium
âœ… Local models (Ollama, LM Studio)
âœ… Agent systems (LangChain, CrewAI)
âœ… Any LLM with file reading capability

### ðŸ“Š Token Efficiency

| Version | Framework Tokens | Code Budget | Protocols |
|---------|------------------|-------------|-----------|
| v2.1 | 25K (all at once) | 175K | 6 (all loaded) |
| v3.0 | 9K (core + 1 protocol) | 191K | 15 (1 loaded) |
| **Improvement** | **64% reduction** | **+9% more space** | **+150% more protocols** |

### ðŸš€ Developer Experience

#### Before (v2.1)
```
1. Load full framework (25K tokens)
2. Choose protocol manually
3. Limited to 1 protocol per session
4. Adding protocols = token overhead
```

#### After (v3.0)
```
1. Load CORE.md (5K tokens)
2. LLM asks what to work on
3. Auto-detects intent and loads protocol
4. Switch protocols seamlessly
5. Add unlimited protocols without overhead
```

### ðŸ”§ Technical Changes

#### New Files
- `CORE.md` - Lightweight entry point with intent detection table
- 15 protocol files in `protocols/` directory

#### Updated Files
- `lib/commands/init.js` - Installs v3.0 structure
- `package.json` - v3.0.0, updated description
- `README.md` - Complete rewrite for v3.0
- `CHANGELOG.md` - This entry

#### Backward Compatibility
- v2.1 files still included (FRAMEWORK.md works as before)
- Users can migrate at their own pace
- `npx ctxforge init` installs both v2.1 and v3.0 files

### ðŸ’¡ Why v3.0 is Revolutionary

#### 1. Cognitive Load Reduction
**v2.1:** "Which protocol do I need? Let me load it manually..."
**v3.0:** Just say what you want. Framework figures it out.

#### 2. Unlimited Scalability
**v2.1:** 10 protocols = 30K overhead (too heavy!)
**v3.0:** 100 protocols = still only 9K per session

#### 3. Multi-Workflow Sessions
Work on multiple types of tasks in one session:
- Morning: Add feature (FEATURE-DEVELOPMENT)
- Afternoon: Fix bugs (BUG-FIXING)
- Evening: Deploy (DEPLOYMENT)

All seamless. All efficient.

#### 4. Future-Proof Architecture
Add custom protocols by creating new files:
```
protocols/
â”œâ”€â”€ custom-ML-TRAINING.md
â”œâ”€â”€ custom-BLOCKCHAIN-AUDIT.md
â””â”€â”€ custom-GAME-LEVEL-DESIGN.md
```

Add to CORE.md intent table. Done.

### ðŸ“š Documentation

- **README.md** - Completely rewritten (v3.0 focused)
- **CORE.md** - New lightweight entry point
- **FRAMEWORK.md** - Updated for v3.0 architecture
- **All 15 protocols** - Complete standalone workflow files
- **example-integrations/** - 12+ platform integration guides

### ðŸ”„ Migration from v2.x

**Good news:** v3.0 is backward compatible!

```bash
# v2.1 command still works
"Read docs/context/FRAMEWORK.md and initialize project"

# v3.0 command (recommended)
"Read docs/context/CORE.md and ask what I want to work on"
```

**To fully migrate:**
1. `npx ctxforge@latest init` (installs v3.0 files)
2. Use new CORE.md entry point
3. Enjoy 60-70% token reduction!

### âš ï¸ Breaking Changes

None. v3.0 is fully backward compatible with v2.1.

### ðŸŽ“ Philosophy

**v2.1:** Load everything, choose protocol manually
**v3.0:** Load intelligently, detect intent automatically

**Key Innovation:** Protocol auto-loading transforms ctxforge from a static framework into an adaptive system that loads exactly what you need, when you need it.

---

## [2.1.0] - 2025-10-02

### âœ¨ New Workflows

#### Bug-Fixing Protocol
- **Discovery-First Debugging** - Ask 3-5 questions before fixing
  - Exact reproduction steps
  - Scope (always/intermittent, which browsers)
  - Recent changes (when did it start)
  - Impact assessment
  - Related issues check
- **Root Cause Analysis** - Hypothesis with confidence level before implementing
- **Solution Proposal** - Show fix + side effects + testing plan
- **Learning Documentation** - Capture why bug happened and prevention rule

#### Refactoring Protocol
- **Understand Before Rewriting** - Ask what needs improvement and what must stay the same
- **Analysis & Proposal** - Show issues, proposed changes, risks before refactoring
- **Incremental Refactoring** - Small reviewable steps, not big-bang rewrites
- **Test Preservation** - Existing tests must pass without modification
- **Learning Capture** - Document patterns that led to messy code

#### Code Review Protocol
- **Multi-Level Review** - Critical â†’ Important â†’ Nice-to-have priorities
- **Quality Score** - Automated scoring against 30 performance directives
- **Actionable Feedback** - Specific fixes, not vague suggestions
- **Best Practices Recognition** - Highlight what's done well
- **Fix Offers** - LLM can implement fixes or explain for human to fix

#### Testing Protocol
- **Test Discovery** - Ask what to test, which type, coverage expectations
- **Test Plan First** - Show test scenarios before writing any code
- **Structured Testing** - Arrange-Act-Assert pattern
- **Coverage Reporting** - Show coverage metrics and missing scenarios
- **Mocking Strategy** - Explicit approach for dependencies

#### Investigation/Debugging Protocol
- **Intent Clarification** - Distinguish "how it works" from "why it's broken"
- **Code Flow Explanation** - High-level flow â†’ key files â†’ data flow
- **Performance Analysis** - Symptoms â†’ investigation â†’ root cause â†’ fix options
- **No Assumptions** - Ask what user wants to understand before explaining

### ðŸ› ï¸ Improvements

#### Mid-Session Context Refresh
- **Framework Reload** - Instructions for LLM to reload protocol mid-conversation
- **Self-Trigger Conditions** - LLM detects when it's not following framework
- **Quick Recovery** - Explicit steps to get back on track

#### Quick Reload Guide
- **QUICK-RELOAD.md** - New reference file for users
- **Symptom Detection** - How to know framework isn't being used
- **Copy-Paste Commands** - Ready-to-use reload instructions
- **Workflow-Specific Reloads** - Separate instructions for bugs vs features vs reviews

### ðŸ“¦ Installation Changes

- **6 Framework Files** (was 5)
  - Added: `QUICK-RELOAD.md` (~3K tokens)
  - Total: ~63K tokens (still well under budget)

### ðŸ”§ Bug Fixes

- **Missing Bug Workflow** - Framework only had feature development, now includes systematic debugging
- **Context Loss** - LLM could forget framework mid-session, now has reload instructions
- **No Review Guidance** - Code review was mentioned but not specified, now has full protocol
- **Testing Vagueness** - "Write tests" had no discovery phase, now systematic

### ðŸ“š Documentation

- **Expanded LLM-INSTRUCTIONS.md** - Added 5 new protocol sections (~400 lines)
- **User Guide** - QUICK-RELOAD.md for when things go wrong
- **Protocol Coverage** - Now covers full development lifecycle:
  - Project initialization âœ“
  - Feature development âœ“
  - Bug fixing âœ“
  - Refactoring âœ“
  - Code review âœ“
  - Testing âœ“
  - Investigation âœ“

## [2.0.0] - 2025-10-02

### ðŸš€ Major Release: Framework v2.0 - Context Discovery

**Complete rewrite focused on lightweight context discovery and universal compatibility.**

### âœ¨ New Features

#### Ultra-Lightweight Framework (81% Reduction)
- **5 Essential Files** (down from 22 files)
  - `FRAMEWORK.md` (12K tokens) - Human-readable introduction
  - `LLM-INSTRUCTIONS.md` (18K tokens) - Complete LLM protocol
  - `PERFORMANCE-DIRECTIVES.md` (15K tokens) - 30 auto-apply quality rules
  - `DISCOVERY-QUESTIONS.md` (8K tokens) - Question templates
  - `TEMPLATES.md` (7K tokens) - Artifact structures
- **60K Total Tokens** (down from 313K - 81% reduction)
- **Zero Configuration** - Copy files and start

#### Context Discovery Protocol
- **Smart Questioning System** - Senior engineer-level question templates
- **Systematic Discovery** - Extract implicit requirements through 5-7 questions
- **Confidence-Scored Inferences** - LLM shows assumptions before coding
  - `[INFER-HIGH]` - Explicit or only reasonable approach
  - `[INFER-MEDIUM]` - Best practice, alternatives exist
  - `[INFER-LOW]` - Assumption, needs confirmation
- **Checkpoint Before Coding** - Human approves/corrects inferences first

#### Universal LLM Compatibility
- Works with **any** LLM (Claude Code, Cursor, ChatGPT, Gemini CLI, local models)
- Pure markdown files (no parsing, no dependencies)
- Technology agnostic (any language/framework)
- Platform independent

#### Automated Quality Enforcement
- 30 performance directives auto-applied
- Big O complexity, accessibility, security standards
- Framework-specific rules (React, Python, Go, Rust, TypeScript)
- No discussion needed - quality by default

#### Context Compression System
- State snapshots after each task (2-4K tokens)
- project.md stays under 20K tokens via compression
- Resume after weeks/months with full context
- Scales to any project size

### ðŸ“¦ Installation Improvements

- **2-Minute Setup** (down from 30 minutes)
- **1-Step Installation** - `npx ctxforge init`
- **No Config Files** - Zero configuration required
- **6 Files Created** - 5 framework + 1 project.md placeholder

### ðŸŽ¯ Developer Experience

#### Simplified Workflow
```
1. npx ctxforge init (2 min)
2. LLM reads FRAMEWORK.md
3. Answer 3 questions â†’ project.md created
4. Describe features â†’ LLM discovers requirements
5. Approve inferences â†’ LLM implements correctly
```

#### Time Savings
- **Discovery:** 5-10 minutes vs 2 hours manual spec writing
- **Implementation:** First-time-right vs multiple rework cycles
- **Context Loading:** 30-40K tokens vs 75-150K tokens

### ðŸ”§ Technical Changes

#### New Structure
```
lib/framework/          # v2.0 (5 files, 60K tokens)
examples/ctxforge-project.md  # Framework applied to itself
```

#### Removed (Archived to ctxforge-v1-archive/)
- `ctxforge-sonnet-4-5-first-dev/` - v1.0 framework (313K tokens)
- `docs/` - Old documentation (200K+ tokens)
- `templates/` - Old templates (53K tokens)
- Development artifacts (SESSION_CONTEXT.md, IMPROVEMENTS.md, etc.)
- Old examples (react-app, python-fastapi)

#### Updated
- `bin/ctxforge.js` - Entry point unchanged
- `lib/commands/init.js` - Installs v2.0 framework
- `package.json` - v2.0.0, updated description and files list
- `README.md` - Complete rewrite for v2.0

### ðŸ“Š Metrics

| Metric | v1.0 | v2.0 | Improvement |
|--------|------|------|-------------|
| Files | 22 | 5 | 77% fewer |
| Total tokens | 313K | 60K | **81% reduction** |
| Install time | 30 min | 2 min | **93% faster** |
| Install steps | 12 | 1 | **92% simpler** |
| Session load | 75-150K | 30-40K | **60-73% lighter** |
| Human effort | Write specs | Answer questions | **90% less work** |
| LLM automation | Manual | Auto-discovery | **Fully automated** |
| Compatibility | 5 documented | ANY LLM | **Universal** |

### ðŸŽ“ Learning System

- **Project Learnings** - Document mistakes, never repeat
- **Learning Entries** - Structured format with prevention strategies
- **Continuous Improvement** - Framework learns from your project

### ðŸ’¡ Philosophy Shift

**v1.0:** Provide comprehensive context files
**v2.0:** Extract context through systematic discovery

**Key Insight:** LLMs have knowledge but lack discovery mechanism. Framework provides senior engineer questioning patterns to extract complete requirements before coding.

### âš ï¸ Breaking Changes

- Complete framework replacement (v1.0 â†’ v2.0 not compatible)
- New installation creates different file structure
- Old `docs/` and `templates/` no longer used
- Migration: Run `npx ctxforge init` to install v2.0

### ðŸ“š Documentation

- **README.md** - Completely rewritten with v2.0 focus
- **FRAMEWORK.md** - New user-facing introduction
- **examples/ctxforge-project.md** - Framework applied to ctxforge itself
- **CLEANUP_V2.md** - Migration and cleanup guide

### ðŸ”„ Migration from v1.0

1. Backup existing project: `cp -r docs ../project-v1-backup`
2. Update package: `npm install ctxforge@2.0.0`
3. Initialize v2.0: `npx ctxforge init`
4. Transfer project info: Answer 3 initialization questions
5. Continue development with v2.0 discovery protocol

### ðŸ™ Credits

Framework v2.0 designed and implemented through collaborative context discovery between Ventsislav Petrov and Claude Sonnet 4.5.

---

## [Unreleased]

### ðŸ”§ Major Refactoring
- **Modular Architecture** - Broke down 2273-line monolithic CLI into focused modules
  - Created `lib/commands/` for command implementations (init, validate, health, status, optimize, spec)
  - Created `lib/utils/` for utility functions (projectDetection, healthCalculation, fileOperations)
  - Reduced main CLI file from 2273 to 157 lines (93% reduction)
  - Each module has single responsibility and is independently testable

### âœ… Testing Infrastructure
- **Test Suite Added** - Implemented real test coverage with Node.js test runner
  - 11 passing tests across 4 test files
  - Tests for project detection, validation, spec generation, and init command
  - Test coverage for utilities and commands
  - Foundation for test-driven development

### ðŸ“š Documentation Improvements
- **Eliminated Duplication** - Removed duplicate documentation directories
  - Removed `docs/quick-start/` (merged into `docs/context/quick-start/`)
  - Removed `docs/templates/` (templates/ is single source of truth)
  - Prevents version drift and reduces maintenance burden

### ðŸ“¦ Examples Structure
- **Example Projects Added** - Created structure for real-world examples
  - React + TypeScript example (planned)
  - Python FastAPI example (planned)
  - Comprehensive learning path documentation

### ðŸ› Fixes
- **package.json** - Removed invalid `main` field (CLI-only package)
- **File Operations** - Fixed documentation copying paths after duplication removal

### ðŸ“– New Documentation
- **IMPROVEMENTS.md** - Comprehensive project analysis and roadmap
- **lib/README.md** - Module organization and migration status
- **examples/README.md** - Guide for using example projects
- **tests/README.md** - Testing conventions and setup

### âš ï¸ Temporarily Disabled Features
The following features are temporarily disabled pending refactoring:
- Guided initialization mode
- Git hooks installation
- IDE setup automation
- Framework metrics dashboard

These will be re-enabled in upcoming releases as they are refactored into the new modular structure.

## [1.2.1] - 2025-10-01

### Documentation
- **Professional Documentation Rewrite** - Improved README.md with technical focus and reduced promotional language
- **Enhanced Installation Instructions** - Clear installation options with examples
- **Professional FAQ Section** - Comprehensive answers to common technical questions
- **Improved Code Examples** - Clean implementation examples without excessive annotations
- **Strategic Icon Usage** - Minimal, purposeful icon usage for better readability

### Technical Improvements
- **Structured Content Organization** - Better section headers and logical flow
- **Comprehensive Framework Description** - Detailed technical specifications and compatibility information
- **Enhanced Quick Start Guide** - Step-by-step instructions with expected outcomes

## [1.2.0] - 2025-10-01

### ðŸš€ Major Features Added
- **Context Discovery System** - Intelligent analysis of user requests with domain expertise
  - `npx ctxforge spec "description"` command for LLM-driven specification generation
  - Smart questioning based on feature type and project context
  - Domain knowledge patterns for common feature types (search, forms, auth, uploads, etc.)
- **Modular Performance Directives** - Broke down 942-line monolith into focused modules
  - 11 specialized directive files by category (algorithmic, security, React, etc.)
  - Task-specific loading strategy for better context economy
  - 75% reduction in irrelevant context loading
- **Context Integration Map** - Comprehensive architectural overview
  - Relationships between all 33+ context files mapped
  - Reading order defined for different workflows
  - SOLID principles applied to context organization

### ðŸŽ¯ Enhanced Features
- **Domain Knowledge Patterns** - Added real-time and mobile development patterns
- **Context Discovery Guide** - LLM methodology for analyzing user requests
- **Specification Generation Guide** - Structured approach to creating behavioral specs
- **Context Economy** - Load only relevant directives based on task type

### ðŸ”§ Improvements
- **LLM Instructions Updated** - Integrated context discovery into core workflow
- **Cross-Stack Support** - Validated with React and Node.js projects
- **Context File Organization** - Single sources of truth established
- **Reference System** - Updated all PD-XXX directive references

### ðŸ§ª Testing & Validation
- **Enhanced Testing** - Comprehensive validation across multiple project types
- **Real-World Scenarios** - File upload, authentication, search features tested
- **Cross-Project Consistency** - Framework works seamlessly across different tech stacks
- **Production Readiness** - All scenarios passed with excellent results

### Technical Details
- Context files modularized following DRY and SOLID principles
- Performance directive loading optimized for specific task types
- Framework architecture redesigned for better maintainability
- Enhanced domain expertise for better LLM guidance

## [1.1.0] - 2025-10-01

### Added
- **Framework Analytics System** - `npx ctxforge metrics` with comprehensive dashboard
- **Development Integration** - `npx ctxforge install-hooks` and `npx ctxforge ide-setup`
- **Enhanced CLI Commands** - `validate`, `status`, `optimize`, `health` commands
- **Progressive Onboarding** - `npx ctxforge guided` with automatic project detection

### Enhanced
- Universal LLM compatibility with improved duplicate detection
- Documentation structure with modular organization
- Context health scoring and optimization recommendations

### Fixed
- Duplication prevention in LLM integration files
- Improved error handling and validation

## [1.0.0] - 2025-01-15

### Added
- Initial release of ctxforge framework
- Core documentation files:
  - README.md - Framework overview
  - quick-start.md - Fast setup guide
  - context-engineering-guide.md - Complete step-by-step process
  - llm-instructions.md - Instructions for LLMs
  - performance-directives.md - Code quality directives
  - framework-summary.md - Framework summary
- Template files:
  - claude-template.md - Main project context template
  - behavioral-spec-template.md - Feature specification template
  - task-execution-protocol.md - Task execution guide
  - project-learnings-template.md - Learning documentation template
  - state-snapshot-template.md - State compression template
- CLI tool (`npx ctxforge init`) for easy framework installation
- npm package support for cross-platform installation
- MIT License

### Features
- Behavior-first specification approach
- Explicit technical inference verification
- Performance-by-default directives
- Atomic task execution model
- Project-specific learning system
- Context compression for long-running projects
- Support for Claude Code, Gemini CLI, ChatGPT, and any LLM
- Language and framework agnostic

[1.2.1]: https://github.com/vencolini/ctxforge/releases/tag/v1.2.1
[1.2.0]: https://github.com/vencolini/ctxforge/releases/tag/v1.2.0
[1.1.0]: https://github.com/vencolini/ctxforge/releases/tag/v1.1.0
[1.0.0]: https://github.com/vencolini/ctxforge/releases/tag/v1.0.0